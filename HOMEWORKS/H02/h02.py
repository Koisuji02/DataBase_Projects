# -*- coding: utf-8 -*-
"""H02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cjcSGMhdIciglUC9Zp5LVOqvEGj6cmtk
"""

!pip install matplotlib
!pip install scikit-learn

# CARICO e IMPORTO LIBRERIE
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import graphviz

# CARICAMENTO DEL DATASET (da excel)
dataframe = pd.read_excel("dataset_breast.xlsx")

# CONTROLLO DEI DATI
print(dataframe.head())
print(dataframe.describe(include='all'))  # Analisi preliminare
print(dataframe.isnull().sum())  # Verifica valori mancanti

# RIMOZIONE DEI DUPLICATI
dataframe_senza_duplicati = dataframe.drop_duplicates()
print(dataframe_senza_duplicati)

# Definizione di features e  labels
X = dataframe_senza_duplicati.drop(columns=['Class'], axis=1)  # Features
y = dataframe_senza_duplicati['Class']  # Label

# PRE-ELABORAZIONE
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

# Identificazione delle colonne categoriche
categorical_features = X.select_dtypes(include=['object']).columns

# Applicazione di LabelEncoder a ogni colonna categorica
for col in categorical_features:
    X[col] = encoder.fit_transform(X[col])

# Applico encoder anche su y
y = encoder.fit_transform(y)

# Verifica del risultato
print(X)

# Suddivisione dei dati in training e test set
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# DECISION TREE BASE: CRITERIO ENTROPY, PROFONDITÀ MAX=5
modello = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)

# Training del modello
modello.fit(X_train, Y_train)

# Predizione sul set di test
Y_pred = modello.predict(X_test)

# Verifica dei risultati
print("Predizioni:", Y_pred[:5])

# Calcolo dell'accuratezza
accuracy = accuracy_score(Y_test, Y_pred)
print(f"Accuratezza del modello: {accuracy:.4f}")

# Imposta la figura per migliorare la leggibilità
plt.figure(figsize=(20, 10))

# VISUALIZZO ALBERO DECISIONALE
plot_tree(modello,
          feature_names=X.columns,  # Nomi delle features
          class_names=[str(c) for c in modello.classes_], # Nomi delle classi
          filled=True,              # Colorazione basata sulla classe
          rounded=True,             # Bordi arrotondati per maggiore leggibilità
          fontsize=10)              # Dimensione del testo

plt.title(f"Albero decisionale con Profondità:{str(modello.get_depth())}")
plt.show()

# Attributo più discriminante
importances = pd.Series(modello.feature_importances_, index=X.columns)
print("Attributo più discriminante:", importances.idxmax())

# Iterazione su parametri (analisi dei parametri su decision teee)
params = [(5, 0.0), (4, 0.02), (3, 0.05), (6, 0.0), (7, 0.01)]
for max_depth, min_impurity_decrease in params:
    modello = DecisionTreeClassifier(criterion='entropy',
                                         max_depth=max_depth,
                                         min_impurity_decrease=min_impurity_decrease,
                                         random_state=42)
    modello.fit(X, y)

    plt.figure(figsize=(20, 10))
    plot_tree(modello, feature_names=X.columns,
              class_names=[str(c) for c in modello.classes_],
              filled=True, rounded=True, fontsize=10)
    plt.title(f"Albero: max_depth={max_depth}, min_impurity_decrease={min_impurity_decrease}")
    plt.show()

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from sklearn.model_selection import StratifiedKFold, cross_val_predict
import matplotlib.pyplot as plt

# Configurazioni dei parametri (fornite)
params = [
    (5, 0.0),  # max_depth=5, min_impurity_decrease=0.0
    (4, 0.02), # max_depth=4, min_impurity_decrease=0.02
    (3, 0.05), # max_depth=3, min_impurity_decrease=0.05
    (6, 0.0),  # max_depth=6, min_impurity_decrease=0.0
    (7, 0.01)  # max_depth=7, min_impurity_decrease=0.01
]

# Valutazione con Stratified 10-fold CV
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Iterazione su ogni configurazione
for i, (max_depth, min_impurity_decrease) in enumerate(params):
    # Configurazione del modello
    model = DecisionTreeClassifier(
        criterion='entropy',
        max_depth=max_depth,
        min_impurity_decrease=min_impurity_decrease,
        random_state=42
    )

    # Cross-validation con predizioni
    y_pred = cross_val_predict(model, X, y, cv=cv)
    cm = confusion_matrix(y, y_pred)
    accuracy = accuracy_score(y, y_pred)

    # Stampa dei risultati
    print(f"Configurazione {i+1}: max_depth={max_depth}, min_impurity_decrease={min_impurity_decrease}")
    print(f"Accuratezza: {accuracy:.4f}")
    print(f"Matrice di confusione:\n{cm}")
    print(classification_report(y, y_pred))

    # Visualizzazione della matrice di confusione
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=encoder.inverse_transform([0, 1]))
    disp.plot(cmap='coolwarm')
    plt.title(f"Confusion Matrix (Config {i+1})")
    plt.show()

from sklearn.model_selection import cross_val_predict, StratifiedKFold
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import matplotlib.pyplot as plt

# Analisi K-NN variando il numero di vicini (K)
k_values = [1, 3, 5, 7, 9]  # Valori di K da analizzare
accuracies_knn = []
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

print("Analisi K-NN variando K:\n")
for k in k_values:
    # Configurazione del classificatore K-NN
    knn_model = KNeighborsClassifier(n_neighbors=k)

    # Cross-validation stratificata con predizioni
    y_pred_knn = cross_val_predict(knn_model, X, y, cv=cv)

    # Matrice di confusione
    cm_knn = confusion_matrix(y, y_pred_knn)
    accuracy_knn = accuracy_score(y, y_pred_knn)
    accuracies_knn.append(accuracy_knn)

    # Stampa dei risultati
    print(f"K={k}")
    print(f"Accuratezza media: {accuracy_knn:.4f}")
    print(f"Matrice di confusione:\n{cm_knn}")

    # Visualizzazione della matrice di confusione
    disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=encoder.inverse_transform([0, 1]))
    disp_knn.plot(cmap='coolwarm')
    plt.title(f"Confusion Matrix (K={k})")
    plt.show()

# Grafico delle accuratezze per i diversi valori di K
plt.figure(figsize=(10, 6))
plt.plot(k_values, accuracies_knn, marker='o', color='blue', label="K-NN Accuracy")
plt.xlabel('Numero di vicini (K)')
plt.ylabel('Accuratezza Media')
plt.title('Prestazioni di K-NN variando K')
plt.grid()
plt.legend()
plt.show()

# Analisi Naïve Bayes
print("\nAnalisi Naïve Bayes:\n")
nb_model = GaussianNB()

# Cross-validation stratificata con predizioni
y_pred_nb = cross_val_predict(nb_model, X, y, cv=cv)
cm_nb = confusion_matrix(y, y_pred_nb)
accuracy_nb = accuracy_score(y, y_pred_nb)

# Stampa dei risultati
print("Naïve Bayes Classifier")
print(f"Accuratezza media: {accuracy_nb:.4f}")
print(f"Matrice di confusione:\n{cm_nb}")

# Visualizzazione della matrice di confusione per Naïve Bayes
disp_nb = ConfusionMatrixDisplay(confusion_matrix=cm_nb, display_labels=encoder.inverse_transform([0, 1]))
disp_nb.plot(cmap='coolwarm')
plt.title("Confusion Matrix (Naïve Bayes)")
plt.show()

# Confronto delle prestazioni
print("\nConfronto delle prestazioni:")
print(f"Accuratezza media migliore di K-NN: {max(accuracies_knn):.4f}")
print(f"Accuratezza media di Naïve Bayes: {accuracy_nb:.4f}")

if max(accuracies_knn) > accuracy_nb:
    print("K-NN si comporta meglio di Naïve Bayes.")
else:
    print("Naïve Bayes si comporta meglio di K-NN.")

# MATRICE DI CORRELAZIONE
correlation_matrix = X.corr()

# Visualizzazione della matrice di correlazione
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, cbar_kws={'shrink': 0.8}, annot_kws={"size": 8})
plt.title("Matrice di Correlazione delle Caratteristiche Numeriche")
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()  # Aggiustamento per evitare il sovraffollamento delle etichette
plt.show()

# Individuare la coppia più correlata (escludendo la correlazione con se stessa)
correlated_pair = correlation_matrix.unstack().sort_values(ascending=False)
# Filtra le correlazioni che non sono tra una variabile e se stessa (1.0)
correlated_pair = correlated_pair[correlated_pair < 1.0]
# Mostra la coppia più correlata
print("Coppia più correlata:", correlated_pair.head(1))